model:
  fusion: txt2img
  K: 1
  prompt_template: "a photo of x x"
  clip_model: "ViT-L/14"
  res_w: 0.8
  SA_K: 1
  width_img: 1024
  width_txt: 768


train:
  dataset: c-fashion
  dataset_path: "/home/yxd/dataset/C-Fashion"
  lr: 0.0005
  attr_dropout: 0.3
  weight_decay: 0.00001
  context_length: 8
  train_batch_size: 32
  gradient_accumulation_steps: 8
  seed: 2134
  epochs: 20
  epoch_start: 0
  save_path: data/model/c-fashion/dfsp
  best_model_metric: best_loss     # 以训练集最低的保存 best_unseen  best_seen AUC best_loss best_hm
  save_model: True
  load_model: False     # False or model path
  att_obj_w: 0.01
  sp_w: 0.1

test:
  eval_batch_size: 32
  open_world: True
  load_model: "data/model/c-fashion/dfsp/txt2img_best.pt"
  topk: 1
  text_encoder_batch_size: 36
  threshold:
  threshold_trials: 20
  bias: 0.001